{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "building_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ebgv/Planet--Understanding-the-Amazon-from-Space/blob/master/building_model_with3rdmodel.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "awDU7mmlvcva",
        "colab_type": "code",
        "outputId": "a2783e8d-2198-42f5-e7d6-52226bd98468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# check the environment \n",
        "\n",
        "%ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S1OG8FpLalVP",
        "colab_type": "code",
        "outputId": "c4b082f3-91a1-48f6-a0cf-48e1dd5d58d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "cell_type": "code",
      "source": [
        "# check if the data is in the environment \n",
        "\n",
        "%cd /content/data/sample/test/cloudy\n",
        "%ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data/sample/test/cloudy\n",
            "train_10421.jpg  train_27120.jpg  train_34205.jpg  train_5541.jpg\n",
            "train_15563.jpg  train_29242.jpg  train_37929.jpg  train_7303.jpg\n",
            "train_23608.jpg  train_30558.jpg  train_38549.jpg  train_7708.jpg\n",
            "train_2396.jpg   train_32526.jpg  train_38804.jpg  train_823.jpg\n",
            "train_24270.jpg  train_32961.jpg  train_4658.jpg   train_8816.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U9ULE4_ibLQm",
        "colab_type": "code",
        "outputId": "d6821d86-7f44-4f87-97d8-f2a7d357005c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "cell_type": "code",
      "source": [
        "# check if the data is in the environment \n",
        "\n",
        "%cd /content/data/sample/train/cloudy\n",
        "%ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/data/sample/train/cloudy\n",
            "train_10269.jpg  train_22919.jpg  train_30364.jpg  train_5216.jpg\n",
            "train_14272.jpg  train_23222.jpg  train_31951.jpg  train_5548.jpg\n",
            "train_16901.jpg  train_23252.jpg  train_33313.jpg  train_6681.jpg\n",
            "train_17814.jpg  train_23443.jpg  train_35846.jpg  train_7414.jpg\n",
            "train_18942.jpg  train_2770.jpg   train_36388.jpg  train_8199.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_UGf6tQ20ez2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports "
      ]
    },
    {
      "metadata": {
        "id": "vDd0uFd2udSm",
        "colab_type": "code",
        "outputId": "8c97f939-0255-4fe9-f116-c6dcfe85aac6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# to install pytorch on colab\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x56c00000 @  0x7f5059a212a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ql1P1A4yus4B",
        "colab_type": "code",
        "outputId": "e4632ae2-50d2-428b-c8ab-e2a401af8913",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U bcolz"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bcolz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/23942de9d5c0fb16f10335fa83e52b431bcb8c0d4a8419c9ac206268c279/bcolz-1.2.1.tar.gz (1.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 9.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from bcolz) (1.14.6)\n",
            "Building wheels for collected packages: bcolz\n",
            "  Running setup.py bdist_wheel for bcolz ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/9f/78/26/fb8c0acb91a100dc8914bf236c4eaa4b207cb876893c40b745\n",
            "Successfully built bcolz\n",
            "Installing collected packages: bcolz\n",
            "Successfully installed bcolz-1.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DgpyYMXsu_IL",
        "colab_type": "code",
        "outputId": "121032ae-178d-464a-d99d-fe749ef0606c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install Pillow==4.0.0"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.6MB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.46)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 5.3.0\n",
            "    Uninstalling Pillow-5.3.0:\n",
            "      Successfully uninstalled Pillow-5.3.0\n",
            "Successfully installed Pillow-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gRTTbDoRlow3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models,transforms,datasets\n",
        "import bcolz\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "45My7S-Y0lCT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# GPU Settings "
      ]
    },
    {
      "metadata": {
        "id": "WM7hZrucl9PE",
        "colab_type": "code",
        "outputId": "82a3022e-48ad-4ce4-b4eb-8d9b9329ddf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "print('Using gpu: %s ' % use_gpu)\n",
        "\n",
        "dtype = torch.FloatTensor\n",
        "if use_gpu:\n",
        "    dtype = torch.cuda.FloatTensor"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using gpu: True \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GwTDQCpm0oJk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Loader"
      ]
    },
    {
      "metadata": {
        "id": "4WVn9nA0wPxX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loader taken from class example: parameters to verify\n",
        "\n",
        "def save_array(fname, arr):\n",
        "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
        "    c.flush()\n",
        "def load_array(fname):\n",
        "    return bcolz.open(fname)[:]\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # statistics from imagenet ? \n",
        "\n",
        "prep1 = transforms.Compose([\n",
        "                transforms.CenterCrop(224), # default cropping \n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H5dXEO_VwY94",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = '/content/data/sample'\n",
        "#data_dir = '/content/data'\n",
        "\n",
        "batch_size = 4\n",
        "#batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fwh58aPbw0V9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dictionary of datasets - in this case only train data set \n",
        "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), prep1)\n",
        "         for x in ['train', 'test']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BHfKaA10ycIf",
        "colab_type": "code",
        "outputId": "ed996262-a3d1-4bef-d0de-24ecd12caa29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "# train labels \n",
        "print(dsets['train'].imgs[:5]) # 5 first images and labels \n",
        "print(dsets['train'].imgs[len(dsets['train'])-5:]) # 5 last images and labels "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('/content/data/sample/train/clear/train_10079.jpg', 0), ('/content/data/sample/train/clear/train_10608.jpg', 0), ('/content/data/sample/train/clear/train_11016.jpg', 0), ('/content/data/sample/train/clear/train_12170.jpg', 0), ('/content/data/sample/train/clear/train_17759.jpg', 0)]\n",
            "[('/content/data/sample/train/partly_cloudy/train_36954.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_5143.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_6072.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_6282.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_834.jpg', 3)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-enxZHd-mHzt",
        "colab_type": "code",
        "outputId": "f3161c6f-9e5a-45af-94e2-a7e154459bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "# test labels \n",
        "print(dsets['test'].imgs[:5]) # 5 first images and labels \n",
        "print(dsets['test'].imgs[len(dsets['test'])-5:]) # 5 last images and labels "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('/content/data/sample/test/clear/train_16269.jpg', 0), ('/content/data/sample/test/clear/train_19920.jpg', 0), ('/content/data/sample/test/clear/train_20175.jpg', 0), ('/content/data/sample/test/clear/train_20853.jpg', 0), ('/content/data/sample/test/clear/train_22936.jpg', 0)]\n",
            "[('/content/data/sample/test/partly_cloudy/train_5514.jpg', 3), ('/content/data/sample/test/partly_cloudy/train_7292.jpg', 3), ('/content/data/sample/test/partly_cloudy/train_7721.jpg', 3), ('/content/data/sample/test/partly_cloudy/train_8085.jpg', 3), ('/content/data/sample/test/partly_cloudy/train_9364.jpg', 3)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x8yvakTTyAmi",
        "colab_type": "code",
        "outputId": "ac39a01d-3a14-4387-f95e-2f15c7ddfe08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "dset_classes = dsets['train'].classes\n",
        "dset_classes # binary classes to begin "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['clear', 'cloudy', 'haze', 'partly_cloudy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "XPtizIgvxUGX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dictionary of data loaders - again only train for now \n",
        "dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=batch_size,\n",
        "                                               shuffle=False, num_workers=0)\n",
        "                for x in ['train', 'test']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "om8qegy4aGrO",
        "colab_type": "code",
        "outputId": "01a90790-cd1b-49e7-d95e-4b3ec47c56e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(dsets['train']))\n",
        "print(len(dsets['test']))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "80\n",
            "80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nnt0LiD61EMJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model: simple classifier from scratch"
      ]
    },
    {
      "metadata": {
        "id": "JpeEpPcrxu9x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# need to understand parameters in more details !!!!\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F # other way to define layers: when no need to update parameters \n",
        "\n",
        "# max pooling layer is not in init: no parameters to update ie. deterministic function  \n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(classifier, self).__init__() # do the init from the inherited class\n",
        "        # then what are the parameters of the network: need to be defined in init \n",
        "        # fill the missing entries below\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1) # check meaning of arguments  \n",
        "        self.fc = nn.Linear(in_features=32*32*64, out_features=4) # 32 = 224 / 7\n",
        "        \n",
        "    def forward(self,x):\n",
        "        # implement your network here, use F.max_pool2d, F.log_softmax and do not forget to flatten your vector\n",
        "        x = self.conv1(x)\n",
        "        x = F.max_pool2d(x, kernel_size=7, stride=7)\n",
        "        x = x.view(-1, 32*32*64) # flatten \n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1) # softmax across the line ! not the component \n",
        "    \n",
        "# since we inherit from nn module, the forward is called by default (do not call classifier.forward() !!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o0GVXkF9Bp2X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model: A bit more complex one"
      ]
    },
    {
      "metadata": {
        "id": "n5gAEy1wBxfF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class NNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(4096, 256)\n",
        "        self.fc2 = nn.Linear(256, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First Conv block:\n",
        "        x = self.conv1(x)\n",
        "        x = F.max_pool2d(x, 5)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        # Second Conv block:\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv2_drop(x)\n",
        "        x = F.max_pool2d(x, 5)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        # Flatten:\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # Classifier:\n",
        "        ## First layer:\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        # Second layer:\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "#model = NNet().cuda() # On GPU"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r1h7QqLAzktS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model vgg16 by hand "
      ]
    },
    {
      "metadata": {
        "id": "X45_ZlO9zjke",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class VGG_16(nn.Module):\n",
        "\n",
        "    def __init__(self,num_classes=4):\n",
        "        super(VGG_16, self).__init__()\n",
        "        self.convblock1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.convblock2 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.convblock3 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.convblock4 = nn.Sequential(\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.convblock5 = nn.Sequential(\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )       \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.convblock1(x)\n",
        "        x = self.convblock2(x)\n",
        "        x = self.convblock3(x)\n",
        "        x = self.convblock4(x)\n",
        "        x = self.convblock5(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "    \n",
        "    def init_weight(self,w):\n",
        "        i=0\n",
        "        for idx, m in enumerate(self.children()):\n",
        "            for idy, msub in enumerate(m.children()):\n",
        "                classname = msub.__class__.__name__\n",
        "                if classname.find('Conv') != -1:\n",
        "                    msub.weight.data = w['features.'+str(i)+'.weight']#.clone()\n",
        "                    msub.bias.data = w['features.'+str(i)+'.bias']#.clone()\n",
        "                    print(msub,'features.'+str(i))\n",
        "                if classname.find('Linear') != -1:\n",
        "                    msub.weight.data = w['classifier.'+str(i-31)+'.weight']#.clone()\n",
        "                    msub.bias.data = w['classifier.'+str(i-31)+'.bias']#.clone()\n",
        "                    print(msub,'classifier.'+str(i-31))\n",
        "                i +=1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NAQHJKIM1Tb4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training Framework"
      ]
    },
    {
      "metadata": {
        "id": "UpnMbim41FNd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model,data_loader,loss_fn,optimizer,n_epochs=1):\n",
        "    \n",
        "    model.train(True)\n",
        "    \n",
        "    loss_train = np.zeros(n_epochs)\n",
        "    acc_train = np.zeros(n_epochs)\n",
        "    \n",
        "    for epoch_num in range(n_epochs):\n",
        "        running_corrects = 0.0\n",
        "        running_loss = 0.0\n",
        "        size = 0\n",
        "\n",
        "        for data in data_loader:\n",
        "            inputs, labels = data\n",
        "            if use_gpu:\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()    \n",
        "                \n",
        "            # batch_size ?\n",
        "            bs = labels.size(0)\n",
        "            \n",
        "            # define the loss to minimize\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            # define the optimizer\n",
        "            optimizer = optimizer\n",
        "            optimizer.zero_grad()\n",
        "            # backpropagation\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # predictions to get statistics \n",
        "            _,preds = torch.max(outputs.data,1)\n",
        "            # statistics\n",
        "            running_loss += loss.data.item()\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            size += bs\n",
        "        # epoch statistics     \n",
        "        epoch_loss = running_loss / size\n",
        "        epoch_acc = running_corrects.item() / size\n",
        "        loss_train[epoch_num] = epoch_loss\n",
        "        acc_train[epoch_num] = epoch_acc\n",
        "        print('Train - Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "        \n",
        "    return loss_train, acc_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w55tUh7AFBkT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Running training epochs"
      ]
    },
    {
      "metadata": {
        "id": "VftjxsGtGKvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "46a3cca2-a800-4158-9a49-35820ddeb49e"
      },
      "cell_type": "code",
      "source": [
        "# instanciate the model \n",
        "model = NNet()\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    model = model.cuda()\n",
        "\n",
        "# choose the appropriate loss\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "# learning rate \n",
        "learning_rate = 1e-3\n",
        "# your SGD optimizer\n",
        "optimizer_cl = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "# and train for 10 epochs\n",
        "l_t, a_t = train(model, dset_loaders['train'], loss_fn, optimizer_cl, n_epochs = 10)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train - Loss: 0.7738 Acc: 0.2500\n",
            "Train - Loss: 0.3606 Acc: 0.0625\n",
            "Train - Loss: 0.3560 Acc: 0.2000\n",
            "Train - Loss: 0.3496 Acc: 0.3750\n",
            "Train - Loss: 0.3438 Acc: 0.4000\n",
            "Train - Loss: 0.3292 Acc: 0.3750\n",
            "Train - Loss: 0.3194 Acc: 0.3750\n",
            "Train - Loss: 0.3207 Acc: 0.4000\n",
            "Train - Loss: 0.3177 Acc: 0.4875\n",
            "Train - Loss: 0.3182 Acc: 0.4625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WmOkkpjhGu_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "05215609-8225-48db-a66c-d20c90210603"
      },
      "cell_type": "code",
      "source": [
        "# and train for 10 epochs\n",
        "l_t, a_t = train(model, dset_loaders['train'], loss_fn, optimizer_cl, n_epochs = 10)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train - Loss: 0.3044 Acc: 0.4750\n",
            "Train - Loss: 0.3367 Acc: 0.3875\n",
            "Train - Loss: 0.3208 Acc: 0.4375\n",
            "Train - Loss: 0.2977 Acc: 0.5250\n",
            "Train - Loss: 0.2948 Acc: 0.5250\n",
            "Train - Loss: 0.2692 Acc: 0.6125\n",
            "Train - Loss: 0.2650 Acc: 0.6000\n",
            "Train - Loss: 0.2569 Acc: 0.6250\n",
            "Train - Loss: 0.3034 Acc: 0.5375\n",
            "Train - Loss: 0.2665 Acc: 0.5375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rTN5VBayz7am",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using vgg 16 by hand "
      ]
    },
    {
      "metadata": {
        "id": "fGHeTjRZz_9_",
        "colab_type": "code",
        "outputId": "508fc279-c7e6-4a83-fa9f-daebc74f48a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "cell_type": "code",
      "source": [
        "# instanciate the model \n",
        "net = VGG_16()\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    net = net.cuda()\n",
        "\n",
        "# choose the appropriate loss\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "# learning rate \n",
        "learning_rate = 1e-3\n",
        "# your SGD optimizer\n",
        "optimizer_cl = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "# and train for 10 epochs\n",
        "l_t, a_t = train(net, dset_loaders['train'], loss_fn, optimizer_cl, n_epochs = 10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-b9f2aa0d6977>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# your SGD optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0moptimizer_cl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'conv_class' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "kdb4r2KZ0x4X",
        "colab_type": "code",
        "outputId": "ba68db61-b4d4-413b-b931-a660c99614a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "# train for 10 more epochs\n",
        "l_t, a_t = train(conv_class, dset_loaders['train'], loss_fn, optimizer_cl, n_epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train - Loss: 2.5555 Acc: 0.6000\n",
            "Train - Loss: 8.0829 Acc: 0.4875\n",
            "Train - Loss: 12.3866 Acc: 0.3375\n",
            "Train - Loss: 3.2874 Acc: 0.5750\n",
            "Train - Loss: 1.4837 Acc: 0.6500\n",
            "Train - Loss: 0.3237 Acc: 0.8625\n",
            "Train - Loss: 0.5194 Acc: 0.8500\n",
            "Train - Loss: 0.3695 Acc: 0.8250\n",
            "Train - Loss: 2.0836 Acc: 0.6375\n",
            "Train - Loss: 1.0061 Acc: 0.7125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "byGcBeJnz4uW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using the simple classfier "
      ]
    },
    {
      "metadata": {
        "id": "I8Xj5NEK1W3J",
        "colab_type": "code",
        "outputId": "f7afa55e-2d09-4475-8fdf-5d036869a5e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "# using the model from scratch\n",
        "\n",
        "# instanciate the model \n",
        "conv_class = classifier()\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    conv_class = conv_class.cuda()\n",
        "\n",
        "# choose the appropriate loss\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "# learning rate \n",
        "learning_rate = 1e-3\n",
        "# your SGD optimizer\n",
        "optimizer_cl = torch.optim.Adam(conv_class.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "# and train for 10 epochs\n",
        "l_t, a_t = train(conv_class, dset_loaders['train'], loss_fn, optimizer_cl, n_epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train - Loss: 4.3163 Acc: 0.4625\n",
            "Train - Loss: 7.1527 Acc: 0.2250\n",
            "Train - Loss: 1.4121 Acc: 0.6000\n",
            "Train - Loss: 3.8656 Acc: 0.4500\n",
            "Train - Loss: 0.9734 Acc: 0.6000\n",
            "Train - Loss: 1.1560 Acc: 0.5875\n",
            "Train - Loss: 0.2495 Acc: 0.8000\n",
            "Train - Loss: 0.5856 Acc: 0.6500\n",
            "Train - Loss: 0.1370 Acc: 0.8625\n",
            "Train - Loss: 0.7864 Acc: 0.5500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YltiFLngZicq",
        "colab_type": "code",
        "outputId": "e6680b17-cc13-472a-9808-53d908be1078",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "# train for 10 more epochs\n",
        "l_t, a_t = train(conv_class, dset_loaders['train'], loss_fn, optimizer_cl, n_epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train - Loss: 1.0411 Acc: 0.5500\n",
            "Train - Loss: 0.2283 Acc: 0.7875\n",
            "Train - Loss: 0.2435 Acc: 0.7875\n",
            "Train - Loss: 0.3782 Acc: 0.7125\n",
            "Train - Loss: 0.0925 Acc: 0.9000\n",
            "Train - Loss: 0.3301 Acc: 0.7625\n",
            "Train - Loss: 0.1617 Acc: 0.9500\n",
            "Train - Loss: 0.0409 Acc: 0.9500\n",
            "Train - Loss: 0.1115 Acc: 0.8875\n",
            "Train - Loss: 0.0597 Acc: 0.9500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6GvEne6jZ4gD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing "
      ]
    },
    {
      "metadata": {
        "id": "YW0txkc1Z_D5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(model,data_loader):\n",
        "    model.train(False)\n",
        "\n",
        "    running_corrects = 0.0\n",
        "    running_loss = 0.0\n",
        "    size = 0\n",
        "\n",
        "    for data in data_loader:\n",
        "        inputs, labels = data\n",
        "        if use_gpu:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "            \n",
        "        bs = labels.size(0)\n",
        "                \n",
        "        outputs = conv_class(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        _,preds = torch.max(outputs.data,1)\n",
        "        \n",
        "        # statistics\n",
        "        running_loss += loss.data.item()\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        size += bs\n",
        "\n",
        "    print('Test - Loss: {:.4f} Acc: {:.4f}'.format(running_loss / size, running_corrects.item() / size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bCReVcCNdPP_",
        "colab_type": "code",
        "outputId": "be1d65d1-a69c-4c4b-92b5-c798c71dbc25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# using simple classifier \n",
        "\n",
        "test(conv_class, dset_loaders['test'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test - Loss: 0.5008 Acc: 0.6125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0rW6GS5kyzCM",
        "colab_type": "code",
        "outputId": "db7e59f5-17e2-4915-d8a9-228172b087d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# using vgg16  \n",
        "\n",
        "test(net, dset_loaders['test'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test - Loss: 1.2838 Acc: 0.5500\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}