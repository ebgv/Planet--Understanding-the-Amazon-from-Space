{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "building_simple_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ebgv/Planet--Understanding-the-Amazon-from-Space/blob/master/building_simple_model.ipynb)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "awDU7mmlvcva",
        "outputId": "66f240d3-cef9-4f9d-b92c-74ea75a1ae10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# check the environment \n",
        "\n",
        "%ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "S1OG8FpLalVP",
        "outputId": "5c3add89-3ba5-4585-fb5c-19e1568946b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "'''# check if the data is in the environment \n",
        "\n",
        "%cd /content/data/sample/test/cloudy\n",
        "%ls'''"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# check if the data is in the environment \\n\\n%cd /content/data/sample/test/cloudy\\n%ls'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "U9ULE4_ibLQm",
        "outputId": "1ac4541c-27b4-4c26-a6df-90c510134767",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "'''# check if the data is in the environment \n",
        "\n",
        "%cd /content/data/sample/train/cloudy\n",
        "%ls'''"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'# check if the data is in the environment \\n\\n%cd /content/data/sample/train/cloudy\\n%ls'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "_UGf6tQ20ez2"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "vDd0uFd2udSm",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# to install pytorch on colab\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Ql1P1A4yus4B",
        "outputId": "ec3d176c-d661-4201-b7f2-6f8b68853910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U bcolz"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: bcolz in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from bcolz) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "DgpyYMXsu_IL",
        "outputId": "55dc8bac-deb2-41f6-ace2-5cf048ba1680",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install Pillow==4.0.0"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==4.0.0\n",
            "  Using cached https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.46)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 5.3.0\n",
            "    Uninstalling Pillow-5.3.0:\n",
            "      Successfully uninstalled Pillow-5.3.0\n",
            "Successfully installed Pillow-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gRTTbDoRlow3",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models,transforms,datasets\n",
        "import bcolz\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "45My7S-Y0lCT"
      },
      "cell_type": "markdown",
      "source": [
        "# GPU Settings "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "WM7hZrucl9PE",
        "outputId": "a099bc17-7498-4f57-ac67-26fb9e1edcd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "print('Using gpu: %s ' % use_gpu)\n",
        "\n",
        "dtype = torch.FloatTensor\n",
        "if use_gpu:\n",
        "    dtype = torch.cuda.FloatTensor"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using gpu: True \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "GwTDQCpm0oJk"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Loader"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4WVn9nA0wPxX",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loader taken from class example: parameters to verify\n",
        "\n",
        "def save_array(fname, arr):\n",
        "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
        "    c.flush()\n",
        "def load_array(fname):\n",
        "    return bcolz.open(fname)[:]\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # statistics from imagenet ? \n",
        "\n",
        "prep1 = transforms.Compose([\n",
        "                transforms.CenterCrop(224), # default cropping \n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "H5dXEO_VwY94",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = '/content/data/sample'\n",
        "#data_dir = '/content/data'\n",
        "\n",
        "#batch_size = 4\n",
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fwh58aPbw0V9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dictionary of datasets - in this case only train data set \n",
        "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), prep1)\n",
        "         for x in ['train', 'test']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "BHfKaA10ycIf",
        "outputId": "3a14a094-a462-4cd0-c957-e3076ae287d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "# train labels \n",
        "print(dsets['train'].imgs[:5]) # 5 first images and labels \n",
        "print(dsets['train'].imgs[len(dsets['train'])-5:]) # 5 last images and labels "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('/content/data/sample/train/clear/train_10002.jpg', 0), ('/content/data/sample/train/clear/train_10095.jpg', 0), ('/content/data/sample/train/clear/train_10190.jpg', 0), ('/content/data/sample/train/clear/train_10194.jpg', 0), ('/content/data/sample/train/clear/train_10226.jpg', 0)]\n",
            "[('/content/data/sample/train/partly_cloudy/train_9827.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_9835.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_9840.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_994.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_9992.jpg', 3)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "-enxZHd-mHzt",
        "outputId": "fb4c6be4-0496-43dd-e122-9cfffe7e38ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "# test labels \n",
        "print(dsets['test'].imgs[:5]) # 5 first images and labels \n",
        "print(dsets['test'].imgs[len(dsets['test'])-5:]) # 5 last images and labels "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('/content/data/sample/test/clear/train_10215.jpg', 0), ('/content/data/sample/test/clear/train_10266.jpg', 0), ('/content/data/sample/test/clear/train_10272.jpg', 0), ('/content/data/sample/test/clear/train_10355.jpg', 0), ('/content/data/sample/test/clear/train_10368.jpg', 0)]\n",
            "[('/content/data/sample/test/partly_cloudy/train_9347.jpg', 3), ('/content/data/sample/test/partly_cloudy/train_9578.jpg', 3), ('/content/data/sample/test/partly_cloudy/train_9641.jpg', 3), ('/content/data/sample/test/partly_cloudy/train_9851.jpg', 3), ('/content/data/sample/test/partly_cloudy/train_9986.jpg', 3)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "x8yvakTTyAmi",
        "outputId": "7b884c16-619e-4b65-b76c-93b629a3dd85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "dset_classes = dsets['train'].classes\n",
        "dset_classes # binary classes to begin "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['clear', 'cloudy', 'haze', 'partly_cloudy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "XPtizIgvxUGX",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dictionary of data loaders - again only train for now \n",
        "dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=batch_size,\n",
        "                                               shuffle=True, num_workers=0)\n",
        "                for x in ['train', 'test']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "om8qegy4aGrO",
        "outputId": "c984fcbf-b000-4d15-d72b-25bf82d210c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(dsets['train']))\n",
        "print(len(dsets['test']))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6400\n",
            "1600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "nnt0LiD61EMJ"
      },
      "cell_type": "markdown",
      "source": [
        "# Model: simple classifier from scratch"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JpeEpPcrxu9x",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# need to understand parameters in more details !!!!\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F # other way to define layers: when no need to update parameters \n",
        "\n",
        "# max pooling layer is not in init: no parameters to update ie. deterministic function  \n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(classifier, self).__init__() # do the init from the inherited class\n",
        "        # then what are the parameters of the network: need to be defined in init \n",
        "        # fill the missing entries below\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1) # check meaning of arguments  \n",
        "        self.fc = nn.Linear(in_features=32*32*64, out_features=4) # 32 = 224 / 7\n",
        "        \n",
        "    def forward(self,x):\n",
        "        # implement your network here, use F.max_pool2d, F.log_softmax and do not forget to flatten your vector\n",
        "        x = self.conv1(x)\n",
        "        x = F.max_pool2d(x, kernel_size=7, stride=7)\n",
        "        x = x.view(-1, 32*32*64) # flatten \n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1) # softmax across the line ! not the component \n",
        "    \n",
        "# since we inherit from nn module, the forward is called by default (do not call classifier.forward() !!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "NAQHJKIM1Tb4"
      },
      "cell_type": "markdown",
      "source": [
        "# Training Framework"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "UpnMbim41FNd",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(model,data_loader,loss_fn,optimizer,n_epochs=1):\n",
        "    \n",
        "    model.train(True)\n",
        "    \n",
        "    loss_train = np.zeros(n_epochs)\n",
        "    acc_train = np.zeros(n_epochs)\n",
        "    \n",
        "    for epoch_num in range(n_epochs):\n",
        "        running_corrects = 0.0\n",
        "        running_loss = 0.0\n",
        "        size = 0\n",
        "\n",
        "        for data in data_loader:\n",
        "            inputs, labels = data\n",
        "            if use_gpu:\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()    \n",
        "                \n",
        "            # batch_size ?\n",
        "            bs = labels.size(0)\n",
        "            \n",
        "            # define the loss to minimize\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            # define the optimizer\n",
        "            optimizer = optimizer\n",
        "            optimizer.zero_grad()\n",
        "            # backpropagation\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # predictions to get statistics \n",
        "            _,preds = torch.max(outputs.data,1)\n",
        "            # statistics\n",
        "            running_loss += loss.data.item()\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            size += bs\n",
        "        # epoch statistics     \n",
        "        epoch_loss = running_loss / size\n",
        "        epoch_acc = running_corrects.item() / size\n",
        "        loss_train[epoch_num] = epoch_loss\n",
        "        acc_train[epoch_num] = epoch_acc\n",
        "        print('Train - Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "        \n",
        "    return loss_train, acc_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "w55tUh7AFBkT"
      },
      "cell_type": "markdown",
      "source": [
        "# Running training epochs"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "byGcBeJnz4uW"
      },
      "cell_type": "markdown",
      "source": [
        "# Using the simple classfier "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "I8Xj5NEK1W3J",
        "outputId": "c1033f60-c483-47a0-c409-f5b02a60b71c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "cell_type": "code",
      "source": [
        "# using the model from scratch\n",
        "\n",
        "# instanciate the model \n",
        "conv_class = classifier()\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    conv_class = conv_class.cuda()\n",
        "\n",
        "# choose the appropriate loss\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "# learning rate \n",
        "learning_rate = 1e-3\n",
        "# your SGD optimizer\n",
        "optimizer_cl = torch.optim.Adam(conv_class.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "# and train for 10 epochs\n",
        "l_t, a_t = train_model(conv_class, dset_loaders['train'], loss_fn, optimizer_cl, n_epochs = 20)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train - Loss: 0.0269 Acc: 0.5914\n",
            "Train - Loss: 0.0131 Acc: 0.6366\n",
            "Train - Loss: 0.0129 Acc: 0.6506\n",
            "Train - Loss: 0.0125 Acc: 0.6633\n",
            "Train - Loss: 0.0117 Acc: 0.6866\n",
            "Train - Loss: 0.0112 Acc: 0.7009\n",
            "Train - Loss: 0.0116 Acc: 0.6942\n",
            "Train - Loss: 0.0107 Acc: 0.7241\n",
            "Train - Loss: 0.0102 Acc: 0.7383\n",
            "Train - Loss: 0.0101 Acc: 0.7370\n",
            "Train - Loss: 0.0096 Acc: 0.7602\n",
            "Train - Loss: 0.0094 Acc: 0.7625\n",
            "Train - Loss: 0.0089 Acc: 0.7777\n",
            "Train - Loss: 0.0086 Acc: 0.7856\n",
            "Train - Loss: 0.0081 Acc: 0.8100\n",
            "Train - Loss: 0.0081 Acc: 0.8048\n",
            "Train - Loss: 0.0078 Acc: 0.8203\n",
            "Train - Loss: 0.0078 Acc: 0.8098\n",
            "Train - Loss: 0.0073 Acc: 0.8277\n",
            "Train - Loss: 0.0069 Acc: 0.8491\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OAd-SrCw4UTN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "9550d7a0-797a-4190-e128-ce0e038d82cc"
      },
      "cell_type": "code",
      "source": [
        "# and train for a few more epochs\n",
        "l_t, a_t = train_model(conv_class, dset_loaders['train'], loss_fn, optimizer_cl, n_epochs = 5)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train - Loss: 0.0065 Acc: 0.8547\n",
            "Train - Loss: 0.0062 Acc: 0.8714\n",
            "Train - Loss: 0.0062 Acc: 0.8658\n",
            "Train - Loss: 0.0060 Acc: 0.8692\n",
            "Train - Loss: 0.0056 Acc: 0.8781\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "6GvEne6jZ4gD"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YW0txkc1Z_D5",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(model,data_loader):\n",
        "    model.train(False)\n",
        "\n",
        "    running_corrects = 0.0\n",
        "    running_loss = 0.0\n",
        "    size = 0\n",
        "\n",
        "    for data in data_loader:\n",
        "        inputs, labels = data\n",
        "        if use_gpu:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "            \n",
        "        bs = labels.size(0)\n",
        "                \n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        _,preds = torch.max(outputs.data,1)\n",
        "        \n",
        "        # statistics\n",
        "        running_loss += loss.data.item()\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        size += bs\n",
        "\n",
        "    print('Test - Loss: {:.4f} Acc: {:.4f}'.format(running_loss / size, running_corrects.item() / size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "bCReVcCNdPP_",
        "outputId": "d5dd9963-c147-4245-bcc7-0d9c66b34acc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# using simple classifier \n",
        "\n",
        "test(conv_class, dset_loaders['test'])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test - Loss: 0.0155 Acc: 0.6675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YnDBdLCF5HRt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}