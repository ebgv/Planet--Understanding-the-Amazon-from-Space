{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "[View in Colaboratory](https://colab.research.google.com/github/ebgv/Planet--Understanding-the-Amazon-from-Space/blob/master/building_simple_model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "awDU7mmlvcva",
    "outputId": "66f240d3-cef9-4f9d-b92c-74ea75a1ae10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdata\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "# check if the data is in the environment \n",
    "\n",
    "#%cd /content/data/sample/train/cloudy\n",
    "#%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_UGf6tQ20ez2"
   },
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "vDd0uFd2udSm"
   },
   "outputs": [],
   "source": [
    "# to install pytorch on colab\n",
    "from os import path\n",
    "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "\n",
    "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
    "\n",
    "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Ql1P1A4yus4B",
    "outputId": "ec3d176c-d661-4201-b7f2-6f8b68853910"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: bcolz in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from bcolz) (1.14.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U bcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 190
    },
    "colab_type": "code",
    "id": "DgpyYMXsu_IL",
    "outputId": "55dc8bac-deb2-41f6-ace2-5cf048ba1680"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Pillow==4.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.46)\n",
      "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: Pillow\n",
      "  Found existing installation: Pillow 5.3.0\n",
      "    Uninstalling Pillow-5.3.0:\n",
      "      Successfully uninstalled Pillow-5.3.0\n",
      "Successfully installed Pillow-4.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow==4.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "gRTTbDoRlow3"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models,transforms,datasets\n",
    "import bcolz\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "45My7S-Y0lCT"
   },
   "source": [
    "# GPU Settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WM7hZrucl9PE",
    "outputId": "a099bc17-7498-4f57-ac67-26fb9e1edcd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu: True \n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print('Using gpu: %s ' % use_gpu)\n",
    "\n",
    "dtype = torch.FloatTensor\n",
    "if use_gpu:\n",
    "    dtype = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GwTDQCpm0oJk"
   },
   "source": [
    "# Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader taken from: https://mlelarge.github.io/dataflowr/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4WVn9nA0wPxX"
   },
   "outputs": [],
   "source": [
    "def save_array(fname, arr):\n",
    "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
    "    c.flush()\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # statistics from imagenet  \n",
    "\n",
    "prep1 = transforms.Compose([\n",
    "                transforms.CenterCrop(224), # default cropping \n",
    "                transforms.ToTensor(),\n",
    "                normalize,\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "H5dXEO_VwY94"
   },
   "outputs": [],
   "source": [
    "data_dir = '/content/data/sample'\n",
    "#data_dir = '/content/data'\n",
    "\n",
    "batch_size = 64\n",
    "#batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fwh58aPbw0V9"
   },
   "outputs": [],
   "source": [
    "# dictionary of datasets \n",
    "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), prep1)\n",
    "         for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "x8yvakTTyAmi",
    "outputId": "7b884c16-619e-4b65-b76c-93b629a3dd85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clear', 'cloudy', 'haze', 'partly_cloudy']"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_classes = dsets['train'].classes\n",
    "dset_classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "XPtizIgvxUGX"
   },
   "outputs": [],
   "source": [
    "# dictionary of data loaders \n",
    "dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=batch_size,\n",
    "                                               shuffle=True, num_workers=0)\n",
    "                for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "BHfKaA10ycIf",
    "outputId": "3a14a094-a462-4cd0-c957-e3076ae287d9",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('/content/data/sample/train/clear/train_10002.jpg', 0), ('/content/data/sample/train/clear/train_10095.jpg', 0), ('/content/data/sample/train/clear/train_10190.jpg', 0), ('/content/data/sample/train/clear/train_10194.jpg', 0), ('/content/data/sample/train/clear/train_10226.jpg', 0)]\n",
      "[('/content/data/sample/train/partly_cloudy/train_9827.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_9835.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_9840.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_994.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_9992.jpg', 3)]\n"
     ]
    }
   ],
   "source": [
    "# train labels \n",
    "print(dsets['train'].imgs[:5]) # 5 first images and labels \n",
    "print(dsets['train'].imgs[len(dsets['train'])-5:]) # 5 last images and labels \n",
    "\n",
    "# test labels \n",
    "print(dsets['test'].imgs[:5]) # 5 first images and labels \n",
    "print(dsets['test'].imgs[len(dsets['test'])-5:]) # 5 last images and labels \n",
    "\n",
    "# data lenght \n",
    "print(len(dsets['train']))\n",
    "print(len(dsets['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nnt0LiD61EMJ"
   },
   "source": [
    "# Model: simple classifier from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "JpeEpPcrxu9x"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  \n",
    "\n",
    "class classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(classifier, self).__init__() \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1)   \n",
    "        self.fc = nn.Linear(in_features=32*32*64, out_features=4) # 32 = 224 / 7\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.max_pool2d(x, kernel_size=7, stride=7)\n",
    "        x = x.view(-1, 32*32*64) \n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NAQHJKIM1Tb4"
   },
   "source": [
    "# Training Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UpnMbim41FNd"
   },
   "outputs": [],
   "source": [
    "def train_model(model,data_loader,loss_fn,optimizer,n_epochs=1):\n",
    "    \n",
    "    model.train(True)\n",
    "    \n",
    "    loss_train = np.zeros(n_epochs)\n",
    "    acc_train = np.zeros(n_epochs)\n",
    "    \n",
    "    for epoch_num in range(n_epochs):\n",
    "        running_corrects = 0.0\n",
    "        running_loss = 0.0\n",
    "        size = 0\n",
    "\n",
    "        for data in data_loader:\n",
    "            inputs, labels = data\n",
    "            if use_gpu:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()    \n",
    "                \n",
    "            bs = labels.size(0)\n",
    "            \n",
    "            # define the loss to minimize\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            # define the optimizer\n",
    "            optimizer = optimizer\n",
    "            optimizer.zero_grad()\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # predictions to get statistics \n",
    "            _,preds = torch.max(outputs.data,1)\n",
    "            # statistics\n",
    "            running_loss += loss.data.item()\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "            size += bs\n",
    "        # epoch statistics     \n",
    "        epoch_loss = running_loss / size\n",
    "        epoch_acc = running_corrects.item() / size\n",
    "        loss_train[epoch_num] = epoch_loss\n",
    "        acc_train[epoch_num] = epoch_acc\n",
    "        print('Train - Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
    "        \n",
    "    return loss_train, acc_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "w55tUh7AFBkT"
   },
   "source": [
    "# Running training epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "byGcBeJnz4uW"
   },
   "source": [
    "# Using the simple classfier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "I8Xj5NEK1W3J",
    "outputId": "c1033f60-c483-47a0-c409-f5b02a60b71c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Loss: 0.0269 Acc: 0.5914\n",
      "Train - Loss: 0.0131 Acc: 0.6366\n",
      "Train - Loss: 0.0129 Acc: 0.6506\n",
      "Train - Loss: 0.0125 Acc: 0.6633\n",
      "Train - Loss: 0.0117 Acc: 0.6866\n",
      "Train - Loss: 0.0112 Acc: 0.7009\n",
      "Train - Loss: 0.0116 Acc: 0.6942\n",
      "Train - Loss: 0.0107 Acc: 0.7241\n",
      "Train - Loss: 0.0102 Acc: 0.7383\n",
      "Train - Loss: 0.0101 Acc: 0.7370\n",
      "Train - Loss: 0.0096 Acc: 0.7602\n",
      "Train - Loss: 0.0094 Acc: 0.7625\n",
      "Train - Loss: 0.0089 Acc: 0.7777\n",
      "Train - Loss: 0.0086 Acc: 0.7856\n",
      "Train - Loss: 0.0081 Acc: 0.8100\n",
      "Train - Loss: 0.0081 Acc: 0.8048\n",
      "Train - Loss: 0.0078 Acc: 0.8203\n",
      "Train - Loss: 0.0078 Acc: 0.8098\n",
      "Train - Loss: 0.0073 Acc: 0.8277\n",
      "Train - Loss: 0.0069 Acc: 0.8491\n"
     ]
    }
   ],
   "source": [
    "# instanciate the model \n",
    "conv_class = classifier()\n",
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    conv_class = conv_class.cuda()\n",
    "\n",
    "# choose the appropriate loss\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# learning rate \n",
    "learning_rate = 1e-3\n",
    "# your optimizer\n",
    "optimizer_cl = torch.optim.Adam(conv_class.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "# and train for 20 epochs\n",
    "l_t, a_t = train_model(conv_class, dset_loaders['train'], loss_fn, optimizer_cl, n_epochs = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6GvEne6jZ4gD"
   },
   "source": [
    "# Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YW0txkc1Z_D5"
   },
   "outputs": [],
   "source": [
    "def test(model,data_loader):\n",
    "    model.train(False)\n",
    "\n",
    "    running_corrects = 0.0\n",
    "    running_loss = 0.0\n",
    "    size = 0\n",
    "\n",
    "    for data in data_loader:\n",
    "        inputs, labels = data\n",
    "        if use_gpu:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "            \n",
    "        bs = labels.size(0)\n",
    "                \n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        _,preds = torch.max(outputs.data,1)\n",
    "        \n",
    "        # statistics\n",
    "        running_loss += loss.data.item()\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "        size += bs\n",
    "\n",
    "    print('Test - Loss: {:.4f} Acc: {:.4f}'.format(running_loss / size, running_corrects.item() / size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bCReVcCNdPP_",
    "outputId": "d5dd9963-c147-4245-bcc7-0d9c66b34acc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - Loss: 0.0155 Acc: 0.6675\n"
     ]
    }
   ],
   "source": [
    "# using simple classifier \n",
    "\n",
    "test(conv_class, dset_loaders['test'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "building_simple_model.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
