{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "building_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ebgv/Planet--Understanding-the-Amazon-from-Space/blob/master/model2_hidden_layers.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "_UGf6tQ20ez2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports "
      ]
    },
    {
      "metadata": {
        "id": "vDd0uFd2udSm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# to install pytorch on colab\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ql1P1A4yus4B",
        "colab_type": "code",
        "outputId": "b742c15b-674a-4a9b-9c76-406985563554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U bcolz"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: bcolz in /usr/local/lib/python3.6/dist-packages (1.2.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from bcolz) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DgpyYMXsu_IL",
        "colab_type": "code",
        "outputId": "a6ab7198-092b-487e-fc9e-5a964da7f7dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install Pillow==4.0.0"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==4.0.0\n",
            "  Using cached https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.46)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 5.3.0\n",
            "    Uninstalling Pillow-5.3.0:\n",
            "      Successfully uninstalled Pillow-5.3.0\n",
            "Successfully installed Pillow-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gRTTbDoRlow3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models,transforms,datasets\n",
        "import bcolz\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "45My7S-Y0lCT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# GPU Settings "
      ]
    },
    {
      "metadata": {
        "id": "WM7hZrucl9PE",
        "colab_type": "code",
        "outputId": "2eb2cc0b-2e53-4a22-b734-7e6f27d8e633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "print('Using gpu: %s ' % use_gpu)\n",
        "\n",
        "dtype = torch.FloatTensor\n",
        "if use_gpu:\n",
        "    dtype = torch.cuda.FloatTensor"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using gpu: True \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GwTDQCpm0oJk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Loader"
      ]
    },
    {
      "metadata": {
        "id": "4WVn9nA0wPxX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loader taken from class example: parameters to verify\n",
        "\n",
        "def save_array(fname, arr):\n",
        "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
        "    c.flush()\n",
        "def load_array(fname):\n",
        "    return bcolz.open(fname)[:]\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # statistics from imagenet ? \n",
        "\n",
        "prep1 = transforms.Compose([\n",
        "                transforms.CenterCrop(224), # default cropping \n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H5dXEO_VwY94",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = '/content/data/sample'\n",
        "#data_dir = '/content/data'\n",
        "\n",
        "#batch_size = 4\n",
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fwh58aPbw0V9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dictionary of datasets - in this case only train data set \n",
        "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), prep1)\n",
        "         for x in ['train', 'test']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BHfKaA10ycIf",
        "colab_type": "code",
        "outputId": "b7f32737-4e73-4c29-a05b-3dcedbdd4197",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "# train labels \n",
        "print(dsets['train'].imgs[:5]) # 5 first images and labels \n",
        "print(dsets['train'].imgs[len(dsets['train'])-5:]) # 5 last images and labels "
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('/content/data/sample/train/clear/train_10.jpg', 0), ('/content/data/sample/train/clear/train_10001.jpg', 0), ('/content/data/sample/train/clear/train_10013.jpg', 0), ('/content/data/sample/train/clear/train_10014.jpg', 0), ('/content/data/sample/train/clear/train_10038.jpg', 0)]\n",
            "[('/content/data/sample/train/partly_cloudy/train_9849.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_9851.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_9892.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_9921.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_9997.jpg', 3)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-enxZHd-mHzt",
        "colab_type": "code",
        "outputId": "e8bfefac-10c0-4ef9-f0a7-8ea7b694f2b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "# test labels \n",
        "print(dsets['test'].imgs[:5]) # 5 first images and labels \n",
        "print(dsets['test'].imgs[len(dsets['test'])-5:]) # 5 last images and labels "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('/content/data/sample/test/clear/train_10077.jpg', 0), ('/content/data/sample/test/clear/train_10155.jpg', 0), ('/content/data/sample/test/clear/train_10198.jpg', 0), ('/content/data/sample/test/clear/train_10315.jpg', 0), ('/content/data/sample/test/clear/train_10369.jpg', 0)]\n",
            "[('/content/data/sample/test/partly_cloudy/train_9552.jpg', 3), ('/content/data/sample/test/partly_cloudy/train_969.jpg', 3), ('/content/data/sample/test/partly_cloudy/train_9720.jpg', 3), ('/content/data/sample/test/partly_cloudy/train_9772.jpg', 3), ('/content/data/sample/test/partly_cloudy/train_994.jpg', 3)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x8yvakTTyAmi",
        "colab_type": "code",
        "outputId": "0f04097c-8002-4437-cfd3-183a03af1940",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "dset_classes = dsets['train'].classes\n",
        "dset_classes # binary classes to begin "
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['clear', 'cloudy', 'haze', 'partly_cloudy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "XPtizIgvxUGX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dictionary of data loaders - again only train for now \n",
        "dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=batch_size,\n",
        "                                               shuffle=True, num_workers=0)\n",
        "                for x in ['train', 'test']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "om8qegy4aGrO",
        "colab_type": "code",
        "outputId": "fc5b0125-dac9-48e4-dea2-998171baaa99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(dsets['train']))\n",
        "print(len(dsets['test']))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6400\n",
            "1600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o0GVXkF9Bp2X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model: A bit more complex one"
      ]
    },
    {
      "metadata": {
        "id": "n5gAEy1wBxfF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(4096, 256)\n",
        "        self.fc2 = nn.Linear(256, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First Conv block:\n",
        "        x = self.conv1(x)\n",
        "        x = F.max_pool2d(x, 5)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        # Second Conv block:\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv2_drop(x)\n",
        "        x = F.max_pool2d(x, 5)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        # Flatten:\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # Classifier:\n",
        "        ## First layer:\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        # Second layer:\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NAQHJKIM1Tb4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training Framework"
      ]
    },
    {
      "metadata": {
        "id": "UpnMbim41FNd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model,data_loader,loss_fn,optimizer,n_epochs=1):\n",
        "    \n",
        "    model.train(True)\n",
        "    \n",
        "    loss_train = np.zeros(n_epochs)\n",
        "    acc_train = np.zeros(n_epochs)\n",
        "    \n",
        "    for epoch_num in range(n_epochs):\n",
        "        running_corrects = 0.0\n",
        "        running_loss = 0.0\n",
        "        size = 0\n",
        "\n",
        "        for data in data_loader:\n",
        "            inputs, labels = data\n",
        "            if use_gpu:\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()    \n",
        "                \n",
        "            # batch_size ?\n",
        "            bs = labels.size(0)\n",
        "            \n",
        "            # define the loss to minimize\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            # define the optimizer\n",
        "            optimizer = optimizer\n",
        "            optimizer.zero_grad()\n",
        "            # backpropagation\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # predictions to get statistics \n",
        "            _,preds = torch.max(outputs.data,1)\n",
        "            # statistics\n",
        "            running_loss += loss.data.item()\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            size += bs\n",
        "        # epoch statistics     \n",
        "        epoch_loss = running_loss / size\n",
        "        epoch_acc = running_corrects.item() / size\n",
        "        loss_train[epoch_num] = epoch_loss\n",
        "        acc_train[epoch_num] = epoch_acc\n",
        "        print('Train - Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "        \n",
        "    return loss_train, acc_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w55tUh7AFBkT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Running training epochs"
      ]
    },
    {
      "metadata": {
        "id": "VftjxsGtGKvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "02100e4e-9c0c-411e-cd2f-73f3d6ffbf72"
      },
      "cell_type": "code",
      "source": [
        "# instanciate the model \n",
        "model = NNet()\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    model = model.cuda()\n",
        "\n",
        "# choose the appropriate loss\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "# learning rate \n",
        "learning_rate = 1e-3\n",
        "# your SGD optimizer\n",
        "optimizer_cl = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "# and train for 20 epochs\n",
        "l_t, a_t = train(model, dset_loaders['train'], loss_fn, optimizer_cl, n_epochs = 20)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train - Loss: 0.0147 Acc: 0.6052\n",
            "Train - Loss: 0.0134 Acc: 0.6516\n",
            "Train - Loss: 0.0129 Acc: 0.6711\n",
            "Train - Loss: 0.0121 Acc: 0.7003\n",
            "Train - Loss: 0.0116 Acc: 0.7119\n",
            "Train - Loss: 0.0109 Acc: 0.7275\n",
            "Train - Loss: 0.0110 Acc: 0.7338\n",
            "Train - Loss: 0.0103 Acc: 0.7569\n",
            "Train - Loss: 0.0100 Acc: 0.7631\n",
            "Train - Loss: 0.0098 Acc: 0.7692\n",
            "Train - Loss: 0.0096 Acc: 0.7731\n",
            "Train - Loss: 0.0095 Acc: 0.7756\n",
            "Train - Loss: 0.0096 Acc: 0.7736\n",
            "Train - Loss: 0.0094 Acc: 0.7822\n",
            "Train - Loss: 0.0093 Acc: 0.7823\n",
            "Train - Loss: 0.0091 Acc: 0.7825\n",
            "Train - Loss: 0.0089 Acc: 0.7945\n",
            "Train - Loss: 0.0087 Acc: 0.7928\n",
            "Train - Loss: 0.0085 Acc: 0.7964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6GvEne6jZ4gD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing "
      ]
    },
    {
      "metadata": {
        "id": "YW0txkc1Z_D5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(model,data_loader):\n",
        "    model.train(False)\n",
        "\n",
        "    running_corrects = 0.0\n",
        "    running_loss = 0.0\n",
        "    size = 0\n",
        "\n",
        "    for data in data_loader:\n",
        "        inputs, labels = data\n",
        "        if use_gpu:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "            \n",
        "        bs = labels.size(0)\n",
        "                \n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        _,preds = torch.max(outputs.data,1)\n",
        "        \n",
        "        # statistics\n",
        "        running_loss += loss.data.item()\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        size += bs\n",
        "\n",
        "    print('Test - Loss: {:.4f} Acc: {:.4f}'.format(running_loss / size, running_corrects.item() / size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OcpLu8PJkida",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9e56ad5a-dcd3-40f8-b3c5-55a5e3f05bd1"
      },
      "cell_type": "code",
      "source": [
        "# using 'hidden'\n",
        "\n",
        "test(model, dset_loaders['test'])"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test - Loss: 0.0089 Acc: 0.7894\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}