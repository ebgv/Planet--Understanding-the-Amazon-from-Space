{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "building_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ebgv/Planet--Understanding-the-Amazon-from-Space/blob/master/model2_hidden_layers.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "_UGf6tQ20ez2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports "
      ]
    },
    {
      "metadata": {
        "id": "vDd0uFd2udSm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "77f4ff4a-4367-4da8-ad35-33d0d14238d7"
      },
      "cell_type": "code",
      "source": [
        "# to install pytorch on colab\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x55e1e000 @  0x7fdf5cfb22a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ql1P1A4yus4B",
        "colab_type": "code",
        "outputId": "94aed057-943c-4931-8255-b3bc735c80a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U bcolz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bcolz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/23942de9d5c0fb16f10335fa83e52b431bcb8c0d4a8419c9ac206268c279/bcolz-1.2.1.tar.gz (1.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from bcolz) (1.14.6)\n",
            "Building wheels for collected packages: bcolz\n",
            "  Running setup.py bdist_wheel for bcolz ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/9f/78/26/fb8c0acb91a100dc8914bf236c4eaa4b207cb876893c40b745\n",
            "Successfully built bcolz\n",
            "Installing collected packages: bcolz\n",
            "Successfully installed bcolz-1.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DgpyYMXsu_IL",
        "colab_type": "code",
        "outputId": "5c4bf013-e2f4-43c2-9e39-2b1a90948f8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install Pillow==4.0.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.6MB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.46)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 5.3.0\n",
            "    Uninstalling Pillow-5.3.0:\n",
            "      Successfully uninstalled Pillow-5.3.0\n",
            "Successfully installed Pillow-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gRTTbDoRlow3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models,transforms,datasets\n",
        "import bcolz\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "45My7S-Y0lCT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# GPU Settings "
      ]
    },
    {
      "metadata": {
        "id": "WM7hZrucl9PE",
        "colab_type": "code",
        "outputId": "c3224ab0-d7ec-49d1-9b86-8960e8e4e721",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "print('Using gpu: %s ' % use_gpu)\n",
        "\n",
        "dtype = torch.FloatTensor\n",
        "if use_gpu:\n",
        "    dtype = torch.cuda.FloatTensor"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using gpu: True \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GwTDQCpm0oJk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Loader"
      ]
    },
    {
      "metadata": {
        "id": "4WVn9nA0wPxX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loader taken from class example: parameters to verify\n",
        "\n",
        "def save_array(fname, arr):\n",
        "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
        "    c.flush()\n",
        "def load_array(fname):\n",
        "    return bcolz.open(fname)[:]\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # statistics from imagenet ? \n",
        "\n",
        "prep1 = transforms.Compose([\n",
        "                transforms.CenterCrop(224), # default cropping \n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H5dXEO_VwY94",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = '/content/data/sample'\n",
        "#data_dir = '/content/data'\n",
        "\n",
        "#batch_size = 4\n",
        "batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fwh58aPbw0V9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dictionary of datasets - in this case only train data set \n",
        "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), prep1)\n",
        "         for x in ['train', 'test']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BHfKaA10ycIf",
        "colab_type": "code",
        "outputId": "cb5a515b-deb8-4db4-962d-f1fc46da6859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "# train labels \n",
        "print(dsets['train'].imgs[:5]) # 5 first images and labels \n",
        "print(dsets['train'].imgs[len(dsets['train'])-5:]) # 5 last images and labels "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('/content/data/sample/train/clear/train_10031.jpg', 0), ('/content/data/sample/train/clear/train_10042.jpg', 0), ('/content/data/sample/train/clear/train_10061.jpg', 0), ('/content/data/sample/train/clear/train_10085.jpg', 0), ('/content/data/sample/train/clear/train_10143.jpg', 0)]\n",
            "[('/content/data/sample/train/partly_cloudy/train_9892.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_9899.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_9913.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_9974.jpg', 3), ('/content/data/sample/train/partly_cloudy/train_9976.jpg', 3)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-enxZHd-mHzt",
        "colab_type": "code",
        "outputId": "344fcf9f-418f-4a59-cdb2-fbb58958189f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "cell_type": "code",
      "source": [
        "# test labels \n",
        "print(dsets['test'].imgs[:5]) # 5 first images and labels \n",
        "print(dsets['test'].imgs[len(dsets['test'])-5:]) # 5 last images and labels "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('/content/data/sample/test/clear/train_10046.jpg', 0), ('/content/data/sample/test/clear/train_10136.jpg', 0), ('/content/data/sample/test/clear/train_10156.jpg', 0), ('/content/data/sample/test/clear/train_10185.jpg', 0), ('/content/data/sample/test/clear/train_1042.jpg', 0)]\n",
            "[('/content/data/sample/test/partly_cloudy/train_9483.jpg', 3), ('/content/data/sample/test/partly_cloudy/train_9520.jpg', 3), ('/content/data/sample/test/partly_cloudy/train_9660.jpg', 3), ('/content/data/sample/test/partly_cloudy/train_9802.jpg', 3), ('/content/data/sample/test/partly_cloudy/train_9979.jpg', 3)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x8yvakTTyAmi",
        "colab_type": "code",
        "outputId": "44a275d6-76be-4918-d641-47da00ee00ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "dset_classes = dsets['train'].classes\n",
        "dset_classes # binary classes to begin "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['clear', 'cloudy', 'haze', 'partly_cloudy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "XPtizIgvxUGX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dictionary of data loaders - again only train for now \n",
        "dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=batch_size,\n",
        "                                               shuffle=True, num_workers=0)\n",
        "                for x in ['train', 'test']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "om8qegy4aGrO",
        "colab_type": "code",
        "outputId": "90b7d43b-e9bd-49d6-c531-c09bfdc250f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(dsets['train']))\n",
        "print(len(dsets['test']))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6400\n",
            "1600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o0GVXkF9Bp2X",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model: A bit more complex one"
      ]
    },
    {
      "metadata": {
        "id": "n5gAEy1wBxfF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class NNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NNet, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 32, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 64, kernel_size=5)\n",
        "        self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(in_features = 4096, out_features = 256)\n",
        "        self.fc2 = nn.Linear(in_features = 256, out_features = 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # First Conv block:\n",
        "        x = self.conv1(x)\n",
        "        x = F.max_pool2d(x, kernel_size = 5, stride = 5)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        # Second Conv block:\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv2_drop(x)\n",
        "        x = F.max_pool2d(x, kernel_size = 5, stride = 5)\n",
        "        x = F.relu(x)\n",
        "        \n",
        "        # Flatten:\n",
        "        x = x.view(x.size(0), -1)\n",
        "        \n",
        "        # Classifier:\n",
        "        ## First layer:\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "        # Second layer:\n",
        "        x = self.fc2(x)\n",
        "        x = F.log_softmax(x, dim=1)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NAQHJKIM1Tb4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training Framework"
      ]
    },
    {
      "metadata": {
        "id": "UpnMbim41FNd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model,data_loader,loss_fn,optimizer,n_epochs=1):\n",
        "    \n",
        "    model.train(True)\n",
        "    \n",
        "    loss_train = np.zeros(n_epochs)\n",
        "    acc_train = np.zeros(n_epochs)\n",
        "    \n",
        "    for epoch_num in range(n_epochs):\n",
        "        running_corrects = 0.0\n",
        "        running_loss = 0.0\n",
        "        size = 0\n",
        "\n",
        "        for data in data_loader:\n",
        "            inputs, labels = data\n",
        "            if use_gpu:\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()    \n",
        "                \n",
        "            # batch_size ?\n",
        "            bs = labels.size(0)\n",
        "            \n",
        "            # define the loss to minimize\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            # define the optimizer\n",
        "            optimizer = optimizer\n",
        "            optimizer.zero_grad()\n",
        "            # backpropagation\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # predictions to get statistics \n",
        "            _,preds = torch.max(outputs.data,1)\n",
        "            # statistics\n",
        "            running_loss += loss.data.item()\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            size += bs\n",
        "        # epoch statistics     \n",
        "        epoch_loss = running_loss / size\n",
        "        epoch_acc = running_corrects.item() / size\n",
        "        loss_train[epoch_num] = epoch_loss\n",
        "        acc_train[epoch_num] = epoch_acc\n",
        "        print('Train - Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "        \n",
        "    return loss_train, acc_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w55tUh7AFBkT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Running training epochs"
      ]
    },
    {
      "metadata": {
        "id": "VftjxsGtGKvy",
        "colab_type": "code",
        "outputId": "0c4649dc-02a6-4f87-c13b-f6a21db8614d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "# instanciate the model \n",
        "model = NNet()\n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    model = model.cuda()\n",
        "\n",
        "# choose the appropriate loss\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "# learning rate \n",
        "learning_rate = 1e-3\n",
        "# your SGD optimizer\n",
        "optimizer_cl = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "# and train for 20 epochs\n",
        "l_t, a_t = train(model, dset_loaders['train'], loss_fn, optimizer_cl, n_epochs = 20)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train - Loss: 0.0146 Acc: 0.6025\n",
            "Train - Loss: 0.0130 Acc: 0.6553\n",
            "Train - Loss: 0.0123 Acc: 0.6852\n",
            "Train - Loss: 0.0119 Acc: 0.6981\n",
            "Train - Loss: 0.0112 Acc: 0.7172\n",
            "Train - Loss: 0.0109 Acc: 0.7297\n",
            "Train - Loss: 0.0107 Acc: 0.7348\n",
            "Train - Loss: 0.0105 Acc: 0.7483\n",
            "Train - Loss: 0.0103 Acc: 0.7544\n",
            "Train - Loss: 0.0101 Acc: 0.7575\n",
            "Train - Loss: 0.0098 Acc: 0.7594\n",
            "Train - Loss: 0.0093 Acc: 0.7739\n",
            "Train - Loss: 0.0092 Acc: 0.7786\n",
            "Train - Loss: 0.0090 Acc: 0.7816\n",
            "Train - Loss: 0.0090 Acc: 0.7792\n",
            "Train - Loss: 0.0090 Acc: 0.7839\n",
            "Train - Loss: 0.0089 Acc: 0.7887\n",
            "Train - Loss: 0.0087 Acc: 0.7861\n",
            "Train - Loss: 0.0083 Acc: 0.7956\n",
            "Train - Loss: 0.0081 Acc: 0.8014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6GvEne6jZ4gD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Testing "
      ]
    },
    {
      "metadata": {
        "id": "YW0txkc1Z_D5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(model,data_loader):\n",
        "    model.train(False)\n",
        "\n",
        "    running_corrects = 0.0\n",
        "    running_loss = 0.0\n",
        "    size = 0\n",
        "\n",
        "    for data in data_loader:\n",
        "        inputs, labels = data\n",
        "        if use_gpu:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "            \n",
        "        bs = labels.size(0)\n",
        "                \n",
        "        outputs = model(inputs)\n",
        "        loss = loss_fn(outputs, labels)\n",
        "        _,preds = torch.max(outputs.data,1)\n",
        "        \n",
        "        # statistics\n",
        "        running_loss += loss.data.item()\n",
        "        running_corrects += torch.sum(preds == labels.data)\n",
        "        size += bs\n",
        "\n",
        "    print('Test - Loss: {:.4f} Acc: {:.4f}'.format(running_loss / size, running_corrects.item() / size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OcpLu8PJkida",
        "colab_type": "code",
        "outputId": "7aac16a0-8d88-49a4-9582-b2732b093807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# using 'hidden'\n",
        "\n",
        "test(model, dset_loaders['test'])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test - Loss: 0.0087 Acc: 0.7844\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}