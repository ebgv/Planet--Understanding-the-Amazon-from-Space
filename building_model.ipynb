{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "building_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ebgv/Planet--Understanding-the-Amazon-from-Space/blob/master/building_model.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "_UGf6tQ20ez2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports "
      ]
    },
    {
      "metadata": {
        "id": "vDd0uFd2udSm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# to install pytorch on colab\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ql1P1A4yus4B",
        "colab_type": "code",
        "outputId": "f8bc2ffe-3578-49cf-9688-8f17e0b423d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U bcolz"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bcolz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/4e/23942de9d5c0fb16f10335fa83e52b431bcb8c0d4a8419c9ac206268c279/bcolz-1.2.1.tar.gz (1.5MB)\n",
            "\u001b[K    100% |████████████████████████████████| 1.5MB 10.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from bcolz) (1.14.6)\n",
            "Building wheels for collected packages: bcolz\n",
            "  Running setup.py bdist_wheel for bcolz ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/9f/78/26/fb8c0acb91a100dc8914bf236c4eaa4b207cb876893c40b745\n",
            "Successfully built bcolz\n",
            "Installing collected packages: bcolz\n",
            "Successfully installed bcolz-1.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DgpyYMXsu_IL",
        "colab_type": "code",
        "outputId": "0cddc9cf-90ac-42fe-e7b1-2ec095528d27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install Pillow==4.0.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Pillow==4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/e8/b3fbf87b0188d22246678f8cd61e23e31caa1769ebc06f1664e2e5fe8a17/Pillow-4.0.0-cp36-cp36m-manylinux1_x86_64.whl (5.6MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.6MB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow==4.0.0) (0.46)\n",
            "\u001b[31mtorchvision 0.2.1 has requirement pillow>=4.1.1, but you'll have pillow 4.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: Pillow\n",
            "  Found existing installation: Pillow 5.3.0\n",
            "    Uninstalling Pillow-5.3.0:\n",
            "      Successfully uninstalled Pillow-5.3.0\n",
            "Successfully installed Pillow-4.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gRTTbDoRlow3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import models,transforms,datasets\n",
        "import bcolz\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "45My7S-Y0lCT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# GPU Settings "
      ]
    },
    {
      "metadata": {
        "id": "WM7hZrucl9PE",
        "colab_type": "code",
        "outputId": "2f2e928a-973d-4c33-9a9f-21fd24740a42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "use_gpu = torch.cuda.is_available()\n",
        "print('Using gpu: %s ' % use_gpu)\n",
        "\n",
        "dtype = torch.FloatTensor\n",
        "if use_gpu:\n",
        "    dtype = torch.cuda.FloatTensor"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using gpu: False \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GwTDQCpm0oJk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Loader"
      ]
    },
    {
      "metadata": {
        "id": "4WVn9nA0wPxX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loader taken from class example: parameters to verify\n",
        "\n",
        "def save_array(fname, arr):\n",
        "    c=bcolz.carray(arr, rootdir=fname, mode='w')\n",
        "    c.flush()\n",
        "def load_array(fname):\n",
        "    return bcolz.open(fname)[:]\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # statistics from imagenet ? \n",
        "\n",
        "prep1 = transforms.Compose([\n",
        "                transforms.CenterCrop(224), # default cropping \n",
        "                transforms.ToTensor(),\n",
        "                normalize,\n",
        "            ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H5dXEO_VwY94",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data_dir = '/content/data/sample'\n",
        "#data_dir = '/content/data'\n",
        "\n",
        "batch_size = 1\n",
        "#batch_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fwh58aPbw0V9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dictionary of datasets - in this case only train data set \n",
        "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), prep1)\n",
        "         for x in ['train']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BHfKaA10ycIf",
        "colab_type": "code",
        "outputId": "421fe3fd-e686-45f2-8735-261683c2bac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "print(dsets['train'].imgs[:5]) # 5 first images and labels \n",
        "print(dsets['train'].imgs[len(dsets['train'])-5:]) # 5 last images and labels "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('/content/data/sample/train/clear/train_1.jpg', 0), ('/content/data/sample/train/clear/train_10.jpg', 0), ('/content/data/sample/train/clear/train_11.jpg', 0), ('/content/data/sample/train/clear/train_13.jpg', 0), ('/content/data/sample/train/clear/train_15.jpg', 0)]\n",
            "[('/content/data/sample/train/cloudy/train_68.jpg', 1), ('/content/data/sample/train/cloudy/train_72.jpg', 1), ('/content/data/sample/train/cloudy/train_77.jpg', 1), ('/content/data/sample/train/cloudy/train_87.jpg', 1), ('/content/data/sample/train/cloudy/train_97.jpg', 1)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x8yvakTTyAmi",
        "colab_type": "code",
        "outputId": "df4c2ae6-92f9-4222-c42a-9e2044a4a997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "dset_classes = dsets['train'].classes\n",
        "dset_classes # binary classes to begin "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['clear', 'cloudy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "XPtizIgvxUGX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# dictionary of data loaders - again only train for now \n",
        "dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=batch_size,\n",
        "                                               shuffle=False, num_workers=0)\n",
        "                for x in ['train']}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nnt0LiD61EMJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model: simple classifier from scratch"
      ]
    },
    {
      "metadata": {
        "id": "JpeEpPcrxu9x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# need to understand parameters in more details !!!!\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F # other way to define layers: when no need to update parameters \n",
        "\n",
        "# max pooling layer is not in init: no parameters to update ie. deterministic function  \n",
        "\n",
        "class classifier(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(classifier, self).__init__() # do the init from the inherited class\n",
        "        # then what are the parameters of the network: need to be defined in init \n",
        "        # fill the missing entries below\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, padding=1) # check meaning of arguments  \n",
        "        self.fc = nn.Linear(in_features=32*32*64, out_features=2)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        # implement your network here, use F.max_pool2d, F.log_softmax and do not forget to flatten your vector\n",
        "        x = self.conv1(x)\n",
        "        x = F.max_pool2d(x, kernel_size=7, stride=7)\n",
        "        x = x.view(-1, 32*32*64) # flatten \n",
        "        x = self.fc(x)\n",
        "        return F.log_softmax(x, dim=1) # softmax across the line ! not the component \n",
        "    \n",
        "# since we inherit from nn module, the forward is called by default (do not call classifier.forward() !!)\n",
        "    \n",
        "use_gpu = torch.cuda.is_available()\n",
        "if use_gpu:\n",
        "    classifier = classifier.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eUPP5_D5EsTl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Model using vgg16"
      ]
    },
    {
      "metadata": {
        "id": "0nYjraw2-zbL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"model_vgg = models.vgg16()\n",
        "\n",
        "for param in model_vgg.parameters():\n",
        "    param.requires_grad = False\n",
        "model_vgg.classifier._modules['6'] = nn.Linear(4096, 2)\n",
        "#model_vgg.classifier[6].out_features = 2\n",
        "#for param in model_vgg.classifier[6].parameters():\n",
        "#    param.requires_grad = True\n",
        "\n",
        "if use_gpu:\n",
        "    model_vgg = model_vgg.cuda()\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NAQHJKIM1Tb4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Training Framework"
      ]
    },
    {
      "metadata": {
        "id": "UpnMbim41FNd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(model,data_loader,loss_fn,optimizer,n_epochs=1):\n",
        "    \n",
        "    model.train(True)\n",
        "    \n",
        "    loss_train = np.zeros(n_epochs)\n",
        "    acc_train = np.zeros(n_epochs)\n",
        "    \n",
        "    for epoch_num in range(n_epochs):\n",
        "        running_corrects = 0.0\n",
        "        running_loss = 0.0\n",
        "        size = 0\n",
        "\n",
        "        for data in data_loader:\n",
        "            inputs, labels = data\n",
        "            if use_gpu:\n",
        "                inputs, labels = inputs.cuda(), labels.cuda()    \n",
        "                \n",
        "            # batch_size\n",
        "            bs = labels.size(0)\n",
        "            \n",
        "            # define the loss to minimize\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            # define the optimizer\n",
        "            optimizer = optimizer\n",
        "            optimizer.zero_grad()\n",
        "            # backpropagation\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # predictions to get statistics \n",
        "            _,preds = torch.max(outputs.data,1)\n",
        "            # statistics\n",
        "            running_loss += loss.data.item()\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            size += bs\n",
        "        # epoch statistics     \n",
        "        epoch_loss = running_loss / size\n",
        "        epoch_acc = running_corrects.item() / size\n",
        "        loss_train[epoch_num] = epoch_loss\n",
        "        acc_train[epoch_num] = epoch_acc\n",
        "        print('Train - Loss: {:.4f} Acc: {:.4f}'.format(epoch_loss, epoch_acc))\n",
        "        \n",
        "    return loss_train, acc_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w55tUh7AFBkT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Running training epochs"
      ]
    },
    {
      "metadata": {
        "id": "I8Xj5NEK1W3J",
        "colab_type": "code",
        "outputId": "bd8e1841-4222-4091-e96e-29ba7636ea35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "# using the model from scratch\n",
        "\n",
        "# instanciate the model \n",
        "conv_class = classifier()\n",
        "\n",
        "# choose the appropriate loss\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "# learning rate \n",
        "learning_rate = 1e-3\n",
        "# your SGD optimizer\n",
        "optimizer_cl = torch.optim.SGD(conv_class.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "# and train for 10 epochs\n",
        "l_t, a_t = train(conv_class,dset_loaders['train'],loss_fn,optimizer_cl,n_epochs = 10)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train - Loss: 0.5180 Acc: 0.8750\n",
            "Train - Loss: 0.7340 Acc: 0.8250\n",
            "Train - Loss: 0.5505 Acc: 0.8250\n",
            "Train - Loss: 1.0344 Acc: 0.9000\n",
            "Train - Loss: 0.2715 Acc: 0.8750\n",
            "Train - Loss: 0.1529 Acc: 0.9250\n",
            "Train - Loss: 0.0946 Acc: 0.9500\n",
            "Train - Loss: 0.0758 Acc: 0.9750\n",
            "Train - Loss: 0.0629 Acc: 1.0000\n",
            "Train - Loss: 0.0536 Acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "50rlK9p82ntb",
        "colab_type": "code",
        "outputId": "94f7f94e-39f2-4290-e785-9ced66e896b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# using vgg16 \n",
        "\n",
        "\"\"\"loss_fn = nn.CrossEntropyLoss()\n",
        "lr = 0.01\n",
        "optimizer_vgg = torch.optim.SGD(model_vgg.classifier[6].parameters(),lr = lr)\n",
        "\n",
        "train(model_vgg.classifier, dset_loaders['train'], loss_fn, n_epochs=10, optimizer=optimizer_vgg)\"\"\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"loss_fn = nn.CrossEntropyLoss()\\nlr = 0.01\\noptimizer_vgg = torch.optim.SGD(model_vgg.classifier[6].parameters(),lr = lr)\\n\\ntrain(model_vgg.classifier, dset_loaders['train'], loss_fn, n_epochs=10, optimizer=optimizer_vgg)\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    }
  ]
}